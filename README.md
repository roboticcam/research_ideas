# research_ideas
My research process is fueled by a constant stream of ideas ðŸ˜Š . Naturally, many are rough drafts - far from being ready for publication. Some turn out to be things others have already done; some I talk myself out of; and others get shot down by my students. (Though, ironically, we sometimes see those 'students-do-not-like' ideas published at top conferences years later by other groups!)

Thatâ€™s why Iâ€™ve decided to start sharing most of these early-stage thoughts more openly. Perhaps a raw idea that didn't make the cut for me will spark inspiration for you and grow into something amazing.

[Idea (1): Employing Reversible Dirichlet Processes for Diffusion-Model-Like Tasks](files/research_idea_1.pdf)

[Idea (2): Combining Markov Chain Monte Carlo and Generative Modeling](files/research_idea_2.pdf)

[Idea (3): Reducing Steps in Diffusion Models](files/research_idea_3.pdf)

[Idea (4): Optimizing Attention Heads Using Determinantal Point Process](files/research_idea_4.pdf)

[Idea (5): HDP-Attention: Mimicking Human Hierarchical Memory for Efficient Long-Context Large Language Models](files/research_idea_5.pdf)

[Idea (6): Correlated Sampling from Multiple Softmax Distributions Using Gumbel-Max Trick and Copulas](files/research_idea_6.pdf)

[Idea (7): ``Elastic'' Attention Mechanism and Sinkhorn Computation](files/research_idea_7.pdf)

[Idea (8): Particle Transformer](files/research_idea_8.pdf)

[Idea (9): NNGP, Transformer and Dirichlet Process Combination](files/research_idea_9.pdf)

[Idea (10): Dirichlet Process (plus Gaussian Process) for combining Flow Matching](files/research_idea_10.pdf)

[Idea (11): Swin Transformer with Semantic Boundary Adherence using Swendsen-Wang Sampling](files/research_idea_11.pdf)

[Idea (12): Multimodal Attention Consistency](files/research_idea_12.pdf)

[Idea (13): Using Diffusion Repainting Mechanism to Achieve Cross-Domain Thinking in Image and Text Watermarking](files/research_idea_13.pdf)
